"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[1531],{1538:(e,n,o)=>{o.r(n),o.d(n,{assets:()=>a,contentTitle:()=>c,default:()=>p,frontMatter:()=>r,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"TechnicalDocs/SDK-intro/buddie-extras/audio-compress","title":"Audio Compression Module (PCA, OPUS)","description":"To transmit audio data over limited BLE bandwidth, we need to compress the audio before transmission. There are two compression methods: PCA and OPUS.","source":"@site/docs/TechnicalDocs/SDK-intro/buddie-extras/audio-compress.mdx","sourceDirName":"TechnicalDocs/SDK-intro/buddie-extras","slug":"/TechnicalDocs/SDK-intro/buddie-extras/audio-compress","permalink":"/open-source-web/docs/TechnicalDocs/SDK-intro/buddie-extras/audio-compress","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/TechnicalDocs/SDK-intro/buddie-extras/audio-compress.mdx","tags":[],"version":"current","frontMatter":{},"sidebar":"TechnicalDocsSidebar","previous":{"title":"Speaker Detection Module","permalink":"/open-source-web/docs/TechnicalDocs/SDK-intro/buddie-extras/vad"},"next":{"title":"Bluetooth Data Transmission and Reception (BLE, SPP)","permalink":"/open-source-web/docs/TechnicalDocs/SDK-intro/buddie-extras/ble-and-spp"}}');var s=o(4848),t=o(8453);const r={},c="Audio Compression Module (PCA, OPUS)",a={},d=[{value:"PCA Compression",id:"pca-compression",level:2},{value:"OPUS Compression",id:"opus-compression",level:2}];function l(e){const n={code:"code",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",ul:"ul",...(0,t.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"audio-compression-module-pca-opus",children:"Audio Compression Module (PCA, OPUS)"})}),"\n",(0,s.jsx)(n.p,{children:"To transmit audio data over limited BLE bandwidth, we need to compress the audio before transmission. There are two compression methods: PCA and OPUS."}),"\n",(0,s.jsx)(n.h2,{id:"pca-compression",children:"PCA Compression"}),"\n",(0,s.jsxs)(n.p,{children:["The main interfaces for this method are implemented in ",(0,s.jsx)(n.code,{children:"cpu\\br28\\fft_and_pca.c"})," and ",(0,s.jsx)(n.code,{children:"cpu\\br28\\fft_and_pca.h"}),". The key functions to pay attention to are:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"hw_fft_init()"}),": This is the initialization function for the FFT calculation module in the PCA compression algorithm. You must execute this function before performing FFT calculations."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"pca_task()"}),": Starts a task to perform PCA compression. This function calls the following methods:","\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"mic_and_spk_data_pop_and_pre_emphasis(s16* emphasized_mic_and_spk_data, int spk_data_count, float sampling_ratio)"}),": Preprocesses (e.g., pre-emphasizes) the audio data obtained from the microphone and speaker (only during calls)."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"dct_transform(s16* input, s16* output)"}),": Performs DCT transformation on the data, converting it from the time domain to the frequency domain, utilizing the FFT module."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"split_sign(s16* input, u8* sign)"}),": Separates the phase information from the frequency domain data into amplitude without sign and phase information represented as 0/1 binary."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"compress_and_add_send_block(s16* spectrum, s8* sign)"}),": After PCA compression of the amplitude information, combines it with the sign information and inputs it into the BLE send queue."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"pca_open()"}),": Performs the above two operations and starts the PCA task."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"transcription_open()"})," and ",(0,s.jsx)(n.code,{children:"transcription_close()"}),": Enable/disable the transcription state of the earphones. When transcription is enabled, it can prevent repeatedly opening the microphone during calls and closing it after calls."]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"opus-compression",children:"OPUS Compression"}),"\n",(0,s.jsxs)(n.p,{children:["The main interfaces for this method are implemented in ",(0,s.jsx)(n.code,{children:"cpu\\br28\\audio_common\\audio_mic_codec.c"})," and ",(0,s.jsx)(n.code,{children:"cpu\\br28\\audio_common\\audio_dec_codec.c"}),", which are used to compress audio data from the microphone and speaker (only during calls), respectively. The key functions to pay attention to are:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"audio_mic_enc_open(int (*mic_output)(void *priv, void *buf, int len), u32 code_type, u8 ai_type)"})," and ",(0,s.jsx)(n.code,{children:"audio_dec_enc_open(int (*dec_output)(void *priv, void *buf, int len), u32 code_type, u8 ai_type)"}),": Enable OPUS transcription for microphone/speaker audio. For specific usage, refer to ",(0,s.jsx)(n.code,{children:"apps\\common\\third_party_profile\\jieli\\JL_rcsp\\bt_trans_data\\le_rcsp_adv_module.c"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"audio_mic_enc_close()"})," and ",(0,s.jsx)(n.code,{children:"audio_dec_enc_close()"}),": Disable OPUS transcription for microphone/speaker audio."]}),"\n"]})]})}function p(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(l,{...e})}):l(e)}},8453:(e,n,o)=>{o.d(n,{R:()=>r,x:()=>c});var i=o(6540);const s={},t=i.createContext(s);function r(e){const n=i.useContext(t);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),i.createElement(t.Provider,{value:n},e.children)}}}]);